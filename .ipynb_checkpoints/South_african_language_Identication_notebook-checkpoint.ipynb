{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c64212cc",
   "metadata": {},
   "source": [
    "# South African Language Identification Hack 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60238b3a",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368efc59",
   "metadata": {},
   "source": [
    "\n",
    "        South Africa is a multicultural society with rich linguistic diversity. \n",
    "        Its 11 official languages hold equal status and play crucial roles in enhancing democracy\n",
    "        and enriching various aspects of social, cultural, economic, and political life. \n",
    "        The majority of South Africans are multilingual, proficient in speaking two or more official languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e37058",
   "metadata": {},
   "source": [
    " #### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39035d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130a193f",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c805f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r\"C:\\Users\\nengo\\Downloads\\south-african-language-identification-hack-2023\\train_set.csv\")\n",
    "test_df = pd.read_csv(r\"C:\\Users\\nengo\\Downloads\\south-african-language-identification-hack-2023\\test_set.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2e8ce0",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1e5c00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45948da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset:\n",
      "  lang_id                                               text\n",
      "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
      "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
      "2     eng  the province of kwazulu-natal department of tr...\n",
      "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
      "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...\n",
      "\n",
      "Test Dataset:\n",
      "   index                                               text\n",
      "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
      "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
      "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
      "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
      "4      5                      Winste op buitelandse valuta.\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Dataset:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nTest Dataset:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec451ad",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2121b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def preprocess_data(train_df, test_df):\n",
    "    # Initializing the Count Vectorizer\n",
    "    vectorizer = CountVectorizer()\n",
    "\n",
    "    # Fitting the vectorizer on the training data\n",
    "    vectorizer.fit(train_df['text'])\n",
    "\n",
    "    # Transforming the training and test data using the fitted vectorizer\n",
    "    train_features = vectorizer.transform(train_df['text'])\n",
    "    test_features = vectorizer.transform(test_df['text'])\n",
    "\n",
    "    return train_features, test_features, vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c83e4513",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, vectorizer = preprocess_data(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95a27415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1 is in en language.\n",
      "Text 2 is in es language.\n",
      "Text 3 is in fr language.\n",
      "Text 4 is in de language.\n",
      "Text 5 is in af language.\n",
      "Text 6 is in hr language.\n",
      "Text 7 is in sw language.\n",
      "Text 8 is in hr language.\n",
      "Text 9 is in sw language.\n",
      "Text 10 is in sw language.\n",
      "Text 11 is in sw language.\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def identify_language(text):\n",
    "    try:\n",
    "        language = detect(text)\n",
    "        return language\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example text in various languages\n",
    "texts = [\n",
    "    \"Hello, how are you?\",                    # English\n",
    "    \"¡Hola! ¿Cómo estás?\",                    # Spanish\n",
    "    \"Bonjour, comment ça va?\",                # French\n",
    "    \"Hallo, wie geht es dir?\",                # German\n",
    "    \"Hoe gaan dit met jou?\",                  # Afrikaans\n",
    "    \"Avuxeni, u njhani?\",                     # Xitsonga\n",
    "    \"Yebo, kunjani?\",                         # Zulu\n",
    "    \"Dumela, o kae?\",                         # Setswana\n",
    "    \"Lefatshe la rona le kgalwa ke wena.\",    # Sesotho\n",
    "    \"Molweni, unjani?\",                       # isiXhosa\n",
    "    \"Salibonani, unjani?\"                     # isiZulu\n",
    "]\n",
    "\n",
    "# Identifying languages for each text\n",
    "for idx, text in enumerate(texts):\n",
    "    language = identify_language(text)\n",
    "    print(f\"Text {idx + 1} is in {language} language.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9e5e36",
   "metadata": {},
   "source": [
    "##  Developing, Training,  Evaluation and Validation using Different Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d969de0",
   "metadata": {},
   "source": [
    "#### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b572c74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## splitting the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_df['lang_id'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f794a21d",
   "metadata": {},
   "source": [
    "## Logistics Regression Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4635f7",
   "metadata": {},
   "source": [
    "#### Using Cross Validation in order to validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e76128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "linearR_model = LogisticRegression()\n",
    "\n",
    "# Train the model using the training data\n",
    "linearR_model.fit(X_train, y_train)\n",
    "\n",
    "# Perform 5-fold cross-validation and calculate F1 score\n",
    "f1_scores = cross_val_score(linearR_model, X_train, y_train, cv=5, scoring='f1_weighted')\n",
    "\n",
    "# Calculate mean F1 score from cross-validation\n",
    "mean_f1_score_cv = f1_scores.mean()\n",
    "print(\"Mean F1 Score (Cross-validation):\", mean_f1_score_cv)\n",
    "\n",
    "# Predict on the validation set (X_val)\n",
    "linearR_preds_val = linearR_model.predict(X_val)\n",
    "\n",
    "# Calculate F1 score on the validation set\n",
    "linearR_f1_val = f1_score(y_val, linearR_preds_val, average='weighted')\n",
    "print(\"F1 Score on Validation Set:\", linearR_f1_val)\n",
    "\n",
    "# Finally, predict and calculate F1 score on the test set (X_test)\n",
    "linearR_preds_test = linearR_model.predict(X_val)\n",
    "linearR_f1_test = f1_score(y_val, linearR_preds_test, average='weighted')\n",
    "print(\"F1 Score on Test Set:\", linearR_f1_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4998f476",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors (KNN) Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba9894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "# Initialize KNN model\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# Define the scorer using F1 score\n",
    "scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# Perform 5-fold cross-validation and calculate F1 score\n",
    "knn_f1_scores = cross_val_score(knn_model, X_train, y_train, cv=5, scoring=scorer)\n",
    "\n",
    "# Calculate mean F1 score from cross-validation\n",
    "mean_f1_score_cv = knn_f1_scores.mean()\n",
    "print(\"Mean F1 Score (Cross-validation):\", mean_f1_score_cv)\n",
    "\n",
    "# Make predictions using cross-validation (on training data)\n",
    "knn_cv_predictions = cross_val_predict(knn_model, X_train, y_train, cv=5)\n",
    "\n",
    "# Fit the model on the entire training data\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set (X_val)\n",
    "knn_val_predictions = knn_model.predict(X_val)\n",
    "\n",
    "# Calculate F1 score on the validation set\n",
    "knn_f1_val = f1_score(y_val, knn_val_predictions, average='weighted')\n",
    "print(\"F1 Score on Validation Set:\", knn_f1_val)\n",
    "\n",
    "# Finally, predict and calculate F1 score on the test set (X_test)\n",
    "knn_test_predictions = knn_model.predict(X_val)\n",
    "knn_f1_test = f1_score(y_val, knn_test_predictions, average='weighted')\n",
    "print(\"F1 Score on Test Set:\", knn_f1_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3914067c",
   "metadata": {},
   "source": [
    "## Support Vector Machine Classification Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54f6392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize SVM classifier\n",
    "svm = SVC()\n",
    "\n",
    "# Train the SVM model using the training data\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set (X_val)\n",
    "svm_predictions = svm.predict(X_val)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(y_val, svm_predictions, average='weighted')\n",
    "recall = recall_score(y_val, svm_predictions, average='weighted')\n",
    "svm_f1 = f1_score(y_val, svm_predictions, average='weighted')\n",
    "\n",
    "print(\"SVM Precision:\", precision)\n",
    "print(\"SVM Recall:\", recall)\n",
    "print(\"SVM F1 Score:\", svm_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631663c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize SVM classifier (you can adjust parameters as needed)\n",
    "svm_classifier = SVC(kernel='rbf', C=1.0, gamma='scale')  \n",
    "\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_val, svm_predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_val, svm_predictions)\n",
    "\n",
    "# Display the confusion matrix using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d655a2df",
   "metadata": {},
   "source": [
    "##  Building the Multinomial Naive Bayes Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_predictions = nb.predict(X_val)\n",
    "nb_f1 = f1_score(y_val, nb_predictions, average='weighted')\n",
    "print(\"Naive Bayes F1 Score:\", nb_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f05138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Initialize Multinomial Naive Bayes model\n",
    "nb = MultinomialNB()\n",
    "\n",
    "#Train Moddel\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "nb_predictions = nb.predict(X_val)\n",
    "\n",
    "# Calculate F1 score on the validation set\n",
    "nb_f1 = f1_score(y_val, nb_predictions, average='weighted')\n",
    "print(\"Naive Bayes F1 Score:\", nb_f1)\n",
    "# Perform 5-fold cross-validation and calculate F1 score\n",
    "f1_scores_cv = cross_val_score(nb, X_train, y_train, cv=5, scoring='f1_weighted')\n",
    "\n",
    "# Calculate mean F1 score from cross-validation\n",
    "mean_f1_score_cv = f1_scores_cv.mean()\n",
    "print(\"Mean F1 Score (Cross-validation):\", mean_f1_score_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461c2e9a",
   "metadata": {},
   "source": [
    "#### Generate predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44da191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using nb Model\n",
    "# Converting the test data into TF-IDF vectors\n",
    "X_test = vectorizer.transform(test_df['text'])\n",
    "\n",
    "# Generating predictions on the best performing model\n",
    "test_predictions = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd3ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Knn_model\n",
    "# Converting the test data into TF-IDF vectors\n",
    "X_test = vectorizer.transform(test_df['text'])\n",
    "\n",
    "# Generating predictions on the best performing model\n",
    "test_predictions = svm.predict(X_test) # svm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f82cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Using Knn_model\n",
    "# Converting the test data into TF-IDF vectors\n",
    "X_test = vectorizer.transform(test_df['text'])\n",
    "\n",
    "# Generating predictions on the best performing model\n",
    "test_predictions = knn_model.predict(X_test) # knn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0692bee2",
   "metadata": {},
   "source": [
    "#### Creating a csv for submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbbdee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a submission dataframe with 'index' and 'lang_id' columns\n",
    "submission_df = pd.DataFrame({'index': test_df['index'], 'lang_id': test_predictions})\n",
    "\n",
    "submission_df.to_csv('FinalSub1.csv', index=False) #nb model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18917203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a submission dataframe with 'index' and 'lang_id' columns\n",
    "submission_df = pd.DataFrame({'index': test_df['index'], 'lang_id': test_predictions})\n",
    "\n",
    "submission_df.to_csv('FinalSub2.csv', index=False) #svm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e328493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a submission dataframe with 'index' and 'lang_id' columns\n",
    "submission_df = pd.DataFrame({'index': test_df['index'], 'lang_id': test_predictions})\n",
    "\n",
    "submission_df.to_csv('FinalSub3.csv', index=False) # knn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8d28e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a submission dataframe with 'index' and 'lang_id' columns\n",
    "submission_df = pd.DataFrame({'index': test_df['index'], 'lang_id': test_predictions})\n",
    "\n",
    "submission_df.to_csv('FinalSub5.csv', index=False) #Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0bac38",
   "metadata": {},
   "source": [
    "## Decision Tree Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf13749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the Decision Tree Classifier\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = decision_tree.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Generate a classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfd73d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Decision Tree Model \n",
    "# Converting the test data into TF-IDF vectors\n",
    "X_test = vectorizer.transform(test_df['text'])\n",
    "\n",
    "# Generating predictions on the best performing model\n",
    "test_predictions = linearR_model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6577ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a submission dataframe with 'index' and 'lang_id' columns\n",
    "submission_df = pd.DataFrame({'index': test_df['index'], 'lang_id': test_predictions})\n",
    "\n",
    "submission_df.to_csv('FinalSub5.csv', index=False) #Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba3ca46",
   "metadata": {},
   "source": [
    "## AdaBoost Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc3601f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78195711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa9037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming train_df contains 'text' column and 'lang_id' as the target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df['text'], train_df['lang_id'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the CountVectorizer on the training text data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Initialize the AdaBoost Classifier\n",
    "adaboost_clf = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# Train the AdaBoost Classifier\n",
    "adaboost_clf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Transform the test data using the same vectorizer\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = adaboost_clf.predict(X_test_vectorized)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Generate a classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, test_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d88835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using AdaBoost classifier Model \n",
    "# Converting the test data into TF-IDF vectors\n",
    "X_test = vectorizer.transform(test_df['text'])\n",
    "\n",
    "# Generating predictions on the best performing model\n",
    "test_predictions = adaboost_clf.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3910b2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a submission dataframe with 'index' and 'lang_id' columns\n",
    "submission_df = pd.DataFrame({'index': test_df['index'], 'lang_id': test_predictions})\n",
    "\n",
    "submission_df.to_csv('FinalSub6.csv', index=False) #Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7617269c",
   "metadata": {},
   "source": [
    "## Neural Network Model Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34307bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Assuming train_df and test_df are your training and test datasets\n",
    "\n",
    "# Preprocessing\n",
    "X_train = train_df['text'].astype(str)\n",
    "y_train = train_df['lang_id']\n",
    "\n",
    "# Splitting the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initializing CountVectorizer and fitting it on the training data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_val_vectorized = vectorizer.transform(X_val)\n",
    "\n",
    "# Build the Neural Network model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train_vectorized.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(len(train_df['lang_id'].unique()), activation='softmax'))  # Adjust output layer units based on unique language IDs\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_vectorized, y_train, epochs=5, batch_size=32, validation_data=(X_val_vectorized, y_val))\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "loss, accuracy = model.evaluate(X_val_vectorized, y_val)\n",
    "print(f'Validation Accuracy: {accuracy}')\n",
    "\n",
    "# Optionally, if you have a test set, you can use it for predictions\n",
    "X_test = test_df['text'].astype(str)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "predictions = model.predict(X_test_vectorized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492743a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize and fit the CountVectorizer on the training data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(train_df['text'])\n",
    "\n",
    "# Transform the test data\n",
    "X_test_vectorized = vectorizer.transform(test_df['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b515aff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the sparse matrix to a pandas DataFrame\n",
    "X_test_vectorized_df = pd.DataFrame.sparse.from_spmatrix(X_test_vectorized)\n",
    "\n",
    "# Concatenating the 'index' column from test_df and the predicted language IDs\n",
    "submission_df = pd.concat([test_df['index'].reset_index(drop=True), X_test_vectorized_df], axis=1)\n",
    "\n",
    "# Saving the DataFrame to a CSV file without row indices\n",
    "submission_df.to_csv('FinalSub7.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb72f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
