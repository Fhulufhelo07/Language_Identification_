{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c64212cc",
   "metadata": {},
   "source": [
    "# South African Language Identification Hack 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60238b3a",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368efc59",
   "metadata": {},
   "source": [
    "\n",
    "        South Africa is a multicultural society with rich linguistic diversity. \n",
    "        Its 11 official languages hold equal status and play crucial roles in enhancing democracy\n",
    "        and enriching various aspects of social, cultural, economic, and political life. \n",
    "        The majority of South Africans are multilingual, proficient in speaking two or more official languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e37058",
   "metadata": {},
   "source": [
    " #### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "39035d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130a193f",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4c805f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r\"C:\\Users\\nengo\\Downloads\\south-african-language-identification-hack-2023\\train_set.csv\")\n",
    "test_df = pd.read_csv(r\"C:\\Users\\nengo\\Downloads\\south-african-language-identification-hack-2023\\test_set.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2e8ce0",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "45948da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset:\n",
      "  lang_id                                               text\n",
      "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
      "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
      "2     eng  the province of kwazulu-natal department of tr...\n",
      "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
      "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...\n",
      "\n",
      "Test Dataset:\n",
      "   index                                               text\n",
      "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
      "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
      "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
      "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
      "4      5                      Winste op buitelandse valuta.\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Dataset:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nTest Dataset:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec451ad",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2121b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_df, test_df):\n",
    "    # Initializing the TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Fitting the vectorizer on the training data\n",
    "    vectorizer.fit(train_df['text'])\n",
    "\n",
    "    # Transforming the training and test data using the fitted vectorizer\n",
    "    train_features = vectorizer.transform(train_df['text'])\n",
    "    test_features = vectorizer.transform(test_df['text'])\n",
    "\n",
    "    return train_features, test_features, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c83e4513",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, vectorizer = preprocess_data(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1b001a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "95a27415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1 is in en language.\n",
      "Text 2 is in es language.\n",
      "Text 3 is in fr language.\n",
      "Text 4 is in de language.\n",
      "Text 5 is in af language.\n",
      "Text 6 is in hr language.\n",
      "Text 7 is in sw language.\n",
      "Text 8 is in hr language.\n",
      "Text 9 is in sw language.\n",
      "Text 10 is in sw language.\n",
      "Text 11 is in sw language.\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def identify_language(text):\n",
    "    try:\n",
    "        language = detect(text)\n",
    "        return language\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example text in various languages\n",
    "texts = [\n",
    "    \"Hello, how are you?\",                    # English\n",
    "    \"¡Hola! ¿Cómo estás?\",                    # Spanish\n",
    "    \"Bonjour, comment ça va?\",                # French\n",
    "    \"Hallo, wie geht es dir?\",                # German\n",
    "    \"Hoe gaan dit met jou?\",                  # Afrikaans\n",
    "    \"Avuxeni, u njhani?\",                     # Xitsonga\n",
    "    \"Yebo, kunjani?\",                         # Zulu\n",
    "    \"Dumela, o kae?\",                         # Setswana\n",
    "    \"Lefatshe la rona le kgalwa ke wena.\",    # Sesotho\n",
    "    \"Molweni, unjani?\",                       # isiXhosa\n",
    "    \"Salibonani, unjani?\"                     # isiZulu\n",
    "]\n",
    "\n",
    "# Identifying languages for each text\n",
    "for idx, text in enumerate(texts):\n",
    "    language = identify_language(text)\n",
    "    print(f\"Text {idx + 1} is in {language} language.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9e5e36",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f794a21d",
   "metadata": {},
   "source": [
    "#### Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "38d4c01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.994245605433102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nengo\\Documents\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_df['lang_id'], test_size=0.2, random_state=42)\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_preds = lr_model.predict(X_val)\n",
    "lr_f1 = f1_score(y_val, lr_preds, average='weighted')\n",
    "\n",
    "print(\"Logistic Regression F1 Score:\", lr_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4998f476",
   "metadata": {},
   "source": [
    "#### K Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bd6a9740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN F1 Score: 0.9593450685034197\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_preds = knn_model.predict(X_val)\n",
    "knn_f1 = f1_score(y_val, knn_preds, average='weighted')\n",
    "\n",
    "print(\"KNN F1 Score:\", knn_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3914067c",
   "metadata": {},
   "source": [
    "#### Support Vector Machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a54f6392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM F1 Score: 0.9942650475719715\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_predictions = svm.predict(X_val)\n",
    "svm_f1 = f1_score(y_val, svm_predictions, average='weighted')\n",
    "print(\"SVM F1 Score:\", svm_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d655a2df",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_predictions = nb.predict(X_val)\n",
    "nb_f1 = f1_score(y_val, nb_predictions, average='weighted')\n",
    "print(\"Naive Bayes F1 Score:\", nb_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461c2e9a",
   "metadata": {},
   "source": [
    "#### Generate predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44da191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the test data into TF-IDF vectors\n",
    "X_test = vectorizer.transform(test_df['text'])\n",
    "\n",
    "# Generating predictions on the best performing model\n",
    "test_predictions = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0692bee2",
   "metadata": {},
   "source": [
    "#### Creating a csv for submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9cbbdee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a submission dataframe with 'index' and 'lang_id' columns\n",
    "submission_df = pd.DataFrame({'index': test_df['index'], 'lang_id': test_predictions})\n",
    "\n",
    "submission_df.to_csv('FinalSub1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd3ed95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
